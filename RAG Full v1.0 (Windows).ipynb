{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'movies_vecdb'\n",
    "DIMENSION = 384\n",
    "URI = 'http://localhost:19530'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "docs = []\n",
    "\n",
    "for file in os.listdir('./movie_text_data/'):\n",
    "    loader = TextLoader(f'./movie_text_data/{file}')\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)  # DA OTTIMIZZARE\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': device}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    drop_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.from_documents(\n",
    "    all_splits,\n",
    "    embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which are the Crime movies directed by Martin Scorsese?\"\n",
    "result = vector_db.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT 1:\n",
      "IMDB ID -> 0031014\n",
      "TITLE -> 6,000 Enemies\n",
      "DIRECTED BY -> George B. Seitz\n",
      "GENRES -> Crime, Drama, Romance\n",
      "PLOT -> A tough prosecutor who has sent dozens of criminals to prison finds himself framed on a bribery charge and winds up in prison himself.\n",
      "YEAR -> 1939\n",
      "STARS -> Walter Pidgeon, Rita Johnson, Paul Kelly\n",
      "\n",
      "DOCUMENT 2:\n",
      "IMDB ID -> 1931533\n",
      "TITLE -> Seven Psychopaths\n",
      "DIRECTED BY -> Martin McDonagh\n",
      "GENRES -> Comedy, Crime\n",
      "PLOT -> A struggling screenwriter inadvertently becomes entangled in the Los Angeles criminal underworld after his oddball friends kidnap a gangster's beloved Shih Tzu.\n",
      "YEAR -> 2012\n",
      "STARS -> Colin Farrell, Woody Harrelson, Sam Rockwell\n",
      "\n",
      "DOCUMENT 3:\n",
      "IMDB ID -> 0037622\n",
      "TITLE -> Crime, Inc.\n",
      "DIRECTED BY -> Lew Landers\n",
      "GENRES -> Crime, Drama, Film-Noir\n",
      "PLOT -> A crusading reporter uses his friendship with a mobster to expose the machinations of organized crime in his city.\n",
      "YEAR -> 1945\n",
      "STARS -> Leo Carrillo, Tom Neal, Martha Tilton\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, doc in enumerate(result):\n",
    "    print(f\"DOCUMENT {n+1}:\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default collection name - LangChainCollection\n",
      "Default search params - {'metric_type': 'L2', 'params': {'ef': 10}}\n",
      "Default index params - None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default collection name - {vector_db.collection_name}\")\n",
    "print(f\"Default search params - {vector_db.search_params}\")\n",
    "print(f\"Default index params - {vector_db.index_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Collection>:\n",
       "-------------\n",
       "<name>: LangChainCollection\n",
       "<description>: \n",
       "<schema>: {'auto_id': True, 'description': '', 'fields': [{'name': 'source', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'pk', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'enable_dynamic_field': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6\n",
      "llama.cpp: loading model from ./models/llama-2-13b-chat.ggmlv3.q4_1.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 3 (mostly Q4_1)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  =  463.77 MB (+  400.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x (640 kB + n_ctx x 160 B) = 360 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 40 repeating layers to GPU\n",
      "llama_model_load_internal: offloading non-repeating layers to GPU\n",
      "llama_model_load_internal: offloading v cache to GPU\n",
      "llama_model_load_internal: offloading k cache to GPU\n",
      "llama_model_load_internal: offloaded 43/43 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 8422 MB\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "        model_path=\"./models/llama-2-13b-chat.ggmlv3.q4_1.bin\",\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=512,\n",
    "        temperature=0.1,\n",
    "        n_threads=8,\n",
    "        max_tokens=16384,\n",
    "        # f16_kv=True,\n",
    "        # callback_manager=CallbackManager(StreamingStdOutCallbackHandler()),\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "Answer to the question in a precise way: use the search results to build the answer, if the asked informations\n",
    "don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "\n",
    "For each movie, report these informations following this structure:\n",
    "- Title\n",
    "- Year\n",
    "- Genre\n",
    "- Director\n",
    "- Brief description of the plot\n",
    "- Main actors\n",
    "\n",
    "Generate a maximum of 5 movies.\n",
    "At the end of your whole answer, you must generate the special token '[END]'. Do not generate other tokens after this one.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Title: Donnie Brasco (1997)\n",
      "Year: 1997\n",
      "Genre: Crime, Drama\n",
      "Director: Mike Newell\n",
      "Brief description of the plot: The film is based on the true story of Joseph D. Pistone, an FBI agent who infiltrated the mafia in the 1970s and 1980s. Johnny Depp plays the role of Benjamin \"Lefty\" Ruggiero, a mobster who becomes a close friend of Pistone's (played by Al Pacino).\n",
      "Main actors: Al Pacino, Johnny Depp, Michael Madsen, Bruno Kirby, and James Russo.\n",
      "\n",
      "[END]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 10645.35 ms\n",
      "llama_print_timings:      sample time =    55.32 ms /   160 runs   (    0.35 ms per token,  2892.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   642.33 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =  9193.50 ms /   159 runs   (   57.82 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:       total time = 10204.97 ms\n"
     ]
    }
   ],
   "source": [
    "resp = rag_chain.invoke(\"Report me one Crime movie or with Johnny Depp\")\n",
    "print(str(resp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
