{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'movies_vecdb'\n",
    "DIMENSION = 384\n",
    "URI = 'http://localhost:19530'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "docs = []\n",
    "\n",
    "for file in os.listdir('./movie_text_data/'):\n",
    "    loader = TextLoader(f'./movie_text_data/{file}')\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)  # DA OTTIMIZZARE\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandropesare/.pyenv/versions/3.10.12/envs/BDRAG/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/alessandropesare/.pyenv/versions/3.10.12/envs/BDRAG/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = None\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': device}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    drop_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Milvus.from_documents(\n",
    "    all_splits,\n",
    "    embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which are the Crime movies directed by Martin Scorsese?\"\n",
    "result = vector_db.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT 1:\n",
      "IMDB ID -> 0031014\n",
      "TITLE -> 6,000 Enemies\n",
      "DIRECTED BY -> George B. Seitz\n",
      "GENRES -> Crime, Drama, Romance\n",
      "PLOT -> A tough prosecutor who has sent dozens of criminals to prison finds himself framed on a bribery charge and winds up in prison himself.\n",
      "YEAR -> 1939\n",
      "STARS -> Walter Pidgeon, Rita Johnson, Paul Kelly\n",
      "\n",
      "DOCUMENT 2:\n",
      "IMDB ID -> 3237082\n",
      "TITLE -> Serial Killer Culture\n",
      "DIRECTED BY -> John Borowski\n",
      "GENRES -> Documentary, Crime, History\n",
      "PLOT -> Serial Killer Culture examines the reasons why artists and collectors are fascinated by serial killers.\n",
      "YEAR -> 2014\n",
      "STARS -> Steve Giannangelo, Rick Staton, Rich Hillen Jr.\n",
      "\n",
      "DOCUMENT 3:\n",
      "IMDB ID -> 0037622\n",
      "TITLE -> Crime, Inc.\n",
      "DIRECTED BY -> Lew Landers\n",
      "GENRES -> Crime, Drama, Film-Noir\n",
      "PLOT -> A crusading reporter uses his friendship with a mobster to expose the machinations of organized crime in his city.\n",
      "YEAR -> 1945\n",
      "STARS -> Leo Carrillo, Tom Neal, Martha Tilton\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, doc in enumerate(result):\n",
    "    print(f\"DOCUMENT {n+1}:\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default collection name - LangChainCollection\n",
      "Default search params - {'metric_type': 'L2', 'params': {'ef': 10}}\n",
      "Default index params - None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default collection name - {vector_db.collection_name}\")\n",
    "print(f\"Default search params - {vector_db.search_params}\")\n",
    "print(f\"Default index params - {vector_db.index_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Collection>:\n",
       "-------------\n",
       "<name>: LangChainCollection\n",
       "<description>: \n",
       "<schema>: {'auto_id': True, 'description': '', 'fields': [{'name': 'source', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'pk', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'enable_dynamic_field': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from ./models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  22:                      quantize.imatrix.file str              = /models/Meta-Llama-3-8B-Instruct-GGUF...\n",
      "llama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = /training_data/groups_merged.txt\n",
      "llama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 88\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  4096.00 MiB, ( 5169.69 /  5461.34)\n",
      "\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =   718.50 MiB, ( 5888.19 /  5461.34)ggml_backend_metal_log_allocated_size: warning: current allocated size is greater than the recommended max working set size\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4403.50 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "llama_kv_cache_init:      Metal KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      Metal compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     9.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'general.quantization_version': '2', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'quantize.imatrix.file': '/models/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.imatrix', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.pre': 'llama-bpe', 'quantize.imatrix.chunks_count': '88', 'tokenizer.ggml.model': 'gpt2', 'llama.vocab_size': '128256', 'llama.attention.head_count_kv': '8', 'llama.context_length': '8192', 'llama.attention.head_count': '32', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'quantize.imatrix.dataset': '/training_data/groups_merged.txt', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '500000.000000', 'llama.embedding_length': '4096', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.block_count': '32'}\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "        model_path=\"./models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\",\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=1024,\n",
    "        temperature=0.2,\n",
    "        n_threads=8,\n",
    "        max_tokens=4096,\n",
    "        # f16_kv=True,\n",
    "        # callback_manager=CallbackManager(StreamingStdOutCallbackHandler()),\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template 1 (forse da rimuovere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "You have to answer to the question in a precise way: you MUST use the search results to build the answer.\n",
    "If the asked informations don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "\n",
    "Generate some movies and, for each movie, report these informations following this structure:\n",
    "* Title: report here the title of the movie\n",
    "* Year: report here the year of the movie\n",
    "* Genre: report here the list of genres for the movie\n",
    "* Director: report here the director \n",
    "* Brief description of the plot: report here a brief description of the plot\n",
    "* Main actors: report here 2 or 3 members of the cast\n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "You have to answer to the question in a precise way: you MUST use the search results to build the answer.\n",
    "If the asked informations don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   10518.49 ms\n",
      "llama_print_timings:      sample time =     127.86 ms /   179 runs   (    0.71 ms per token,  1400.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10517.90 ms /   154 tokens (   68.30 ms per token,    14.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17722.33 ms /   178 runs   (   99.56 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =   31199.53 ms /   332 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies Directed by Spike Lee with Specific Features:\n",
      "\n",
      "1. **Do the Right Thing (1989)** - This film is directed by Spike Lee and corresponds to the feature \"the movie directed by Spike Lee\".\n",
      "2. **Malcolm X (1992)** - This film is directed by Spike Lee, stars Denzel Washington, and corresponds to the features \"the movie directed by Spike Lee\" and \"a movie starring Denzel Washington\".\n",
      "3. **25th Hour (2002)** - This film is directed by Spike Lee, stars Edward Norton, and corresponds to the features \"the movie directed by Spike Lee\" and \"a movie starring Edward Norton\".\n",
      "\n",
      "I chose these movies because they all meet at least one of the specified criteria: being directed by Spike Lee. The movies also have additional features that make them stand out, such as starring notable actors like Denzel Washington or Edward Norton.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which correspond to at least one of these features: the movie directed by Spike Lee.\n",
    "Give more importance to a movie if it corresponds to more than one of the listed features.\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: input query --> a famous movie \"Titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10518.49 ms\n",
      "llama_print_timings:      sample time =     924.39 ms /   190 runs   (    4.87 ms per token,   205.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8960.12 ms /    28 tokens (  320.00 ms per token,     3.12 tokens per second)\n",
      "llama_print_timings:        eval time =  257791.62 ms /   189 runs   ( 1363.98 ms per token,     0.73 tokens per second)\n",
      "llama_print_timings:       total time =  326119.75 ms /   217 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some movies that are similar to \"Titanic\":\n",
      "\n",
      "1. **The Poseidon Adventure** (1972) - This disaster movie also features a catastrophic event at sea, where passengers must fight for survival.\n",
      "\n",
      "2. **A Night to Remember** (1958) - This British drama film is based on the true story of the RMS Titanic's sinking. The film focuses on the personal stories of the passengers and crew.\n",
      "\n",
      "3. **The Unsinkable Molly Brown** (1964) - This biographical musical comedy-drama film tells the story of Margaret \"Molly\" Brown, a wealthy socialite who survived the sinking of the RMS Titanic.\n",
      "\n",
      "I chose these movies because they all share similar themes with \"Titanic\", such as disaster, survival, romance, and tragedy. They also feature strong characters, dramatic plot twists, and memorable music, which are all key elements that make \"Titanic\" so iconic and beloved.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which are similar to \"Titanic\".\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: input query --> generic movies \"Just Before I Go\" and \"Deewaar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10518.49 ms\n",
      "llama_print_timings:      sample time =     692.50 ms /   195 runs   (    3.55 ms per token,   281.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9327.40 ms /    40 tokens (  233.19 ms per token,     4.29 tokens per second)\n",
      "llama_print_timings:        eval time =  140445.04 ms /   194 runs   (  723.94 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =  182613.77 ms /   234 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some movies that are similar to \"Just Before I Go\" and \"Deewaar\":\n",
      "\n",
      "1. **The Breakfast Club** (1985) - This classic John Hughes film explores themes of identity, social class, and the struggles of adolescence.\n",
      "2. **Stand by Me** (1986) - Based on a novella by Stephen King, this coming-of-age drama follows four young friends as they embark on a journey to find the body of a missing boy.\n",
      "3. **The Perks of Being a Wallflower** (2012) - This coming-of-age drama follows Charlie, a shy and introverted teenager, as he navigates his freshman year of high school and struggles with mental health issues.\n",
      "\n",
      "I chose these movies because they all share similar themes and elements to \"Just Before I Go\" and \"Deewaar\". They are all coming-of-age stories that explore the struggles and challenges faced by teenagers as they navigate their way through adolescence.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which are similar to \"Just Before I go\" or \"Deewaar\".\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: input query --> generic movies with different features in AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10518.49 ms\n",
      "llama_print_timings:      sample time =    1005.27 ms /   183 runs   (    5.49 ms per token,   182.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7371.58 ms /    36 tokens (  204.77 ms per token,     4.88 tokens per second)\n",
      "llama_print_timings:        eval time =  171061.17 ms /   182 runs   (  939.90 ms per token,     1.06 tokens per second)\n",
      "llama_print_timings:       total time =  230175.28 ms /   218 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies Similar to \"Sniper: Ghost Shooter\" and \"Lady Ice\":\n",
      "\n",
      "1. **The Accountant** (2016) - This action-thriller stars Ben Affleck as a socially awkward accountant who moonlights as an assassin.\n",
      "2. **Atomic Blonde** (2017) - Set in 1980s Berlin, this spy thriller follows Charlize Theron's character, Lorraine Broughton, a top-level spy sent to Berlin to take down a espionage ring.\n",
      "3. **The Bourne Legacy** (2012) - This action-thriller is part of the Jason Bourne series and stars Jeremy Renner as Aaron Cross, a highly trained assassin suffering from memory loss.\n",
      "\n",
      "I chose these movies because they share similar themes and elements with \"Sniper: Ghost Shooter\" and \"Lady Ice\". They all feature high-stakes action sequences, complex characters, and intricate plots.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which are similar to \"Sniper: Ghost Shooter\" and \"Lady Ice\".\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: input query --> generic movies with very different features in AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10518.49 ms\n",
      "llama_print_timings:      sample time =     957.06 ms /   173 runs   (    5.53 ms per token,   180.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4304.55 ms /    36 tokens (  119.57 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:        eval time =  228255.00 ms /   172 runs   ( 1327.06 ms per token,     0.75 tokens per second)\n",
      "llama_print_timings:       total time =  279139.75 ms /   208 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies Similar to \"Chasing Ghosts: Beyond the Arcade\" and \"Dancin': It's on!\":\n",
      "\n",
      "1. **The King of Kong: A Fistful of Quarters** (2007) - This documentary-style comedy film is about a group of gamers competing in a Donkey Kong tournament.\n",
      "2. **The Gamers: Dorkness Rising** (2008) - This mockumentary film follows a group of friends who are obsessed with tabletop role-playing games.\n",
      "3. **Win, Lose or Draw** (1989) - This family-friendly game show features contestants competing in various drawing challenges.\n",
      "\n",
      "I chose these movies because they all share elements of competition, gaming, and camaraderie that are similar to the themes found in \"Chasing Ghosts: Beyond the Arcade\" and \"Dancin': It's on!\".\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which are similar to \"Chasing Ghosts: Beyond the Arcade\" or \"Dancin': It's on!\".\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
