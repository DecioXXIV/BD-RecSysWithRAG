{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandropesare/.pyenv/versions/3.10.12/envs/BDRAG/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/alessandropesare/.pyenv/versions/3.10.12/envs/BDRAG/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = None\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': device}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prima Sezione -> Interazione con Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 58022\n",
      "Required Time: 0:00:10.171321\n"
     ]
    }
   ],
   "source": [
    "# Questo Blocco di Codice serve per effettuare lo Splitting dei Documenti memorizzati in \"movie_text_data\"\n",
    "docs = list()\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "for file in os.listdir('../movie_text_data/'):\n",
    "    loader = TextLoader(f'../movie_text_data/{file}')\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)  # DA OTTIMIZZARE\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connessione a Milvus (deve essere prima fatto partire il Container su Docker!)\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    drop_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Time: 0:07:51.790059\n"
     ]
    }
   ],
   "source": [
    "# Attenzione!!! Il seguente Blocco di Codice reinizializza Milvus ed esegue il Caricamento dei Documenti memorizzati in 'all_splits'ArithmeticError\n",
    "start = datetime.now()\n",
    "\n",
    "vector_db = Milvus.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    collection_name=\"MovieTextData\",\n",
    "    drop_old=True\n",
    ")\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default collection name - LangChainCollection\n",
      "Default search params - None\n",
      "Default index params - None\n"
     ]
    }
   ],
   "source": [
    "# Esegui il seguente Blocco di Codice per ottenere informazioni sulla Collezione in Milvus\n",
    "print(f\"Default collection name - {vector_db.collection_name}\")\n",
    "print(f\"Default search params - {vector_db.search_params}\")\n",
    "print(f\"Default index params - {vector_db.index_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda Sezione -> Inizializzazione di Llama3-8b-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from ../models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  22:                      quantize.imatrix.file str              = /models/Meta-Llama-3-8B-Instruct-GGUF...\n",
      "llama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = /training_data/groups_merged.txt\n",
      "llama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 88\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  4096.00 MiB, ( 5152.38 /  5461.34)\n",
      "\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =   718.50 MiB, ( 5870.88 /  5461.34)ggml_backend_metal_log_allocated_size: warning: current allocated size is greater than the recommended max working set size\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   281.81 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4403.50 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "llama_kv_cache_init:      Metal KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      Metal compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     9.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'general.quantization_version': '2', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'quantize.imatrix.file': '/models/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.imatrix', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.pre': 'llama-bpe', 'quantize.imatrix.chunks_count': '88', 'tokenizer.ggml.model': 'gpt2', 'llama.vocab_size': '128256', 'llama.attention.head_count_kv': '8', 'llama.context_length': '8192', 'llama.attention.head_count': '32', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'quantize.imatrix.dataset': '/training_data/groups_merged.txt', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '500000.000000', 'llama.embedding_length': '4096', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.block_count': '32'}\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "        model_path=\"../models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\",\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=1024,\n",
    "        temperature=0.2,\n",
    "        n_threads=8,\n",
    "        max_tokens=8192,\n",
    "        # f16_kv=True,\n",
    "        # callback_manager=CallbackManager(StreamingStdOutCallbackHandler()),\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terza Sezione -> Recupero delle Preferenze di un certo User (per ora, uno User a scelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/alessandropesare/software/GitHub/BD-RecSysWithRAG/\")\n",
    "from inf_retriever import InfRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST\n",
    "Users--> 111,400,7,95,8115,280,322,294,5661,15003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = InfRetriever(userId=5661)     # User scelto arbitrariamente\n",
    "ir.computeUserPreferences(sample_size=10)   \n",
    "\n",
    "# Il metodo 'computeUserPreferences' esegue le seguenti operazioni:\n",
    "#   1) Recupera gli ID dei Film a cui lo User ha dato almeno '4.5' come punteggio\n",
    "#   2) Campiona 'sample_size' di questi Film -> Attenzione! Se il valore di 'sample_size' è maggiore del numero di Film 'candidati'\n",
    "#       questo automaticamente assume il valore 'int(0.67*len(candidati))'ArithmeticError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bridges of Madison County, The (1995)',\n",
       " 'Apollo 13 (1995)',\n",
       " 'Clear and Present Danger (1994)',\n",
       " 'Net, The (1995)',\n",
       " 'Disclosure (1994)',\n",
       " 'Lion King, The (1994)',\n",
       " 'Fugitive, The (1993)',\n",
       " 'Crimson Tide (1995)',\n",
       " 'Piano, The (1993)',\n",
       " 'Dolores Claiborne (1995)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = ir.getMovieTitles()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>genres</th>\n",
       "      <th>plot</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The Bridges of Madison County</td>\n",
       "      <td>Clint Eastwood</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>Photographer Robert Kincaid wanders into the l...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Clint Eastwood, Meryl Streep, Annie Corley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Apollo 13</td>\n",
       "      <td>Ron Howard</td>\n",
       "      <td>Adventure, Drama, History</td>\n",
       "      <td>NASA must devise a strategy to return Apollo 1...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Tom Hanks, Bill Paxton, Kevin Bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Clear and Present Danger</td>\n",
       "      <td>Phillip Noyce</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>CIA Analyst Jack Ryan is drawn into an illegal...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Harrison Ford, Willem Dafoe, Anne Archer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>The Net</td>\n",
       "      <td>Irwin Winkler</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>When Angela Bennett, a computer programmer, st...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Sandra Bullock, Jeremy Northam, Dennis Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Disclosure</td>\n",
       "      <td>Barry Levinson</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>A computer specialist is sued for sexual haras...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Michael Douglas, Demi Moore, Donald Sutherland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>Roger Allers</td>\n",
       "      <td>Animation, Adventure, Drama</td>\n",
       "      <td>Lion prince Simba and his father are targeted ...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Matthew Broderick, Jeremy Irons, James Earl Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>The Fugitive</td>\n",
       "      <td>Andrew Davis</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>Dr. Richard Kimble, unjustly accused of murder...</td>\n",
       "      <td>1993</td>\n",
       "      <td>Harrison Ford, Tommy Lee Jones, Sela Ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Crimson Tide</td>\n",
       "      <td>Tony Scott</td>\n",
       "      <td>Action, Drama, Thriller</td>\n",
       "      <td>On a U.S. nuclear missile sub, a young First O...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Gene Hackman, Denzel Washington, Matt Craven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>The Piano</td>\n",
       "      <td>Jane Campion</td>\n",
       "      <td>Drama, Music, Romance</td>\n",
       "      <td>In the mid-19th century a mute woman is sent t...</td>\n",
       "      <td>1993</td>\n",
       "      <td>Holly Hunter, Harvey Keitel, Sam Neill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Dolores Claiborne</td>\n",
       "      <td>Taylor Hackford</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>A big city reporter travels to a small town wh...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Kathy Bates, Jennifer Jason Leigh, Christopher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title         director  \\\n",
       "105  The Bridges of Madison County   Clint Eastwood   \n",
       "150                      Apollo 13       Ron Howard   \n",
       "349       Clear and Present Danger    Phillip Noyce   \n",
       "185                        The Net    Irwin Winkler   \n",
       "225                     Disclosure   Barry Levinson   \n",
       "364                  The Lion King     Roger Allers   \n",
       "457                   The Fugitive     Andrew Davis   \n",
       "161                   Crimson Tide       Tony Scott   \n",
       "509                      The Piano     Jane Campion   \n",
       "230              Dolores Claiborne  Taylor Hackford   \n",
       "\n",
       "                          genres  \\\n",
       "105               Drama, Romance   \n",
       "150    Adventure, Drama, History   \n",
       "349         Action, Crime, Drama   \n",
       "185         Action, Crime, Drama   \n",
       "225              Drama, Thriller   \n",
       "364  Animation, Adventure, Drama   \n",
       "457         Action, Crime, Drama   \n",
       "161      Action, Drama, Thriller   \n",
       "509        Drama, Music, Romance   \n",
       "230        Crime, Drama, Mystery   \n",
       "\n",
       "                                                  plot  year  \\\n",
       "105  Photographer Robert Kincaid wanders into the l...  1995   \n",
       "150  NASA must devise a strategy to return Apollo 1...  1995   \n",
       "349  CIA Analyst Jack Ryan is drawn into an illegal...  1994   \n",
       "185  When Angela Bennett, a computer programmer, st...  1995   \n",
       "225  A computer specialist is sued for sexual haras...  1994   \n",
       "364  Lion prince Simba and his father are targeted ...  1994   \n",
       "457  Dr. Richard Kimble, unjustly accused of murder...  1993   \n",
       "161  On a U.S. nuclear missile sub, a young First O...  1995   \n",
       "509  In the mid-19th century a mute woman is sent t...  1993   \n",
       "230  A big city reporter travels to a small town wh...  1995   \n",
       "\n",
       "                                                  cast  \n",
       "105         Clint Eastwood, Meryl Streep, Annie Corley  \n",
       "150                Tom Hanks, Bill Paxton, Kevin Bacon  \n",
       "349           Harrison Ford, Willem Dafoe, Anne Archer  \n",
       "185      Sandra Bullock, Jeremy Northam, Dennis Miller  \n",
       "225     Michael Douglas, Demi Moore, Donald Sutherland  \n",
       "364  Matthew Broderick, Jeremy Irons, James Earl Jones  \n",
       "457          Harrison Ford, Tommy Lee Jones, Sela Ward  \n",
       "161       Gene Hackman, Denzel Washington, Matt Craven  \n",
       "509             Holly Hunter, Harvey Keitel, Sam Neill  \n",
       "230  Kathy Bates, Jennifer Jason Leigh, Christopher...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = ir.getMovieDetailsDF()\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarta Sezione -> generazione delle Raccomandazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "You have to answer to the request in a precise way and strictly following what is asked: you MUST use the search results to build the answer.\n",
    "If the asked informations don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\"\n",
    "\n",
    "rec_prompt = PromptTemplate.from_template(rec_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | rec_prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10721.62 ms\n",
      "llama_print_timings:      sample time =    1073.03 ms /   185 runs   (    5.80 ms per token,   172.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9210.70 ms /    27 tokens (  341.14 ms per token,     2.93 tokens per second)\n",
      "llama_print_timings:        eval time =  403931.11 ms /   184 runs   ( 2195.28 ms per token,     0.46 tokens per second)\n",
      "llama_print_timings:       total time =  492125.22 ms /   211 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some movies that are similar to \"Disclosure\":\n",
      "\n",
      "1. **The Net** (1995) - This movie also explores themes of surveillance and privacy in a high-tech world.\n",
      "\n",
      "2. **Enemy of the State** (1998) - This action-comedy film, starring Will Smith, also deals with government surveillance and corruption.\n",
      "\n",
      "3. **Minority Report** (2002) - Based on Philip K. Dick's short story, this sci-fi thriller explores themes of free will and predestination in a world where crimes can be predicted and prevented.\n",
      "\n",
      "4. **The Truman Show** (1998) - This satirical film, directed by Peter Weir, also explores the theme of surveillance and control in a seemingly ordinary life.\n",
      "\n",
      "I chose these movies because they all share similar themes with \"Disclosure\", such as government surveillance, privacy concerns, and the blurring of lines between public and private spaces.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which are similar to \"Disclosure\".\n",
    "After reporting the movies, explain why you chose them.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
