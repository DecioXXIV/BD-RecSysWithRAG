{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione del Device\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prima Sezione -> Interazione con Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 58022\n",
      "Required Time: 0:07:07.848427\n"
     ]
    }
   ],
   "source": [
    "# Questo Blocco di Codice serve per effettuare lo Splitting dei Documenti memorizzati in \"movie_text_data\"\n",
    "docs = list()\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "for file in os.listdir('./movie_text_data/'):\n",
    "    loader = TextLoader(f'./movie_text_data/{file}')\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)  # DA OTTIMIZZARE\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione del Modello di Embedding -> all-MiniLM-L12-v2 (HuggingFace, len(Spazio Latente)=384)\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': device}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connessione a Milvus (deve essere prima fatto partire il Container su Docker!)\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    drop_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Time: 0:01:30.029326\n"
     ]
    }
   ],
   "source": [
    "# Attenzione!!! Il seguente Blocco di Codice reinizializza Milvus ed esegue il Caricamento dei Documenti memorizzati in 'all_splits'ArithmeticError\n",
    "start = datetime.now()\n",
    "\n",
    "vector_db = Milvus.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    collection_name=\"MovieTextData\",\n",
    "    drop_old=True\n",
    ")\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default collection name - MovieTextData\n",
      "Default search params - {'metric_type': 'L2', 'params': {'ef': 10}}\n",
      "Default index params - {'metric_type': 'L2', 'index_type': 'HNSW', 'params': {'M': 8, 'efConstruction': 64}}\n"
     ]
    }
   ],
   "source": [
    "# Esegui il seguente Blocco di Codice per ottenere informazioni sulla Collezione in Milvus\n",
    "print(f\"Default collection name - {vector_db.collection_name}\")\n",
    "print(f\"Default search params - {vector_db.search_params}\")\n",
    "print(f\"Default index params - {vector_db.index_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda Sezione -> Inizializzazione di Llama3-8b-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/Meta-Llama-3-8B-Instruct-Q6_K.gguf\"\n",
    "n_threads = int(os.cpu_count()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ./models/Meta-Llama-3-8B-Instruct-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   410.98 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  5871.99 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 1024\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '18', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|end_of_text|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=1024,\n",
    "        temperature=0.1,\n",
    "        n_threads=n_threads,\n",
    "        max_tokens=8192,\n",
    "        n_ctx=2048,\n",
    "        # f16_kv=True,\n",
    "        # callback_manager=CallbackManager(StreamingStdOutCallbackHandler()),\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terza Sezione -> Recupero delle Preferenze di un certo User (per ora, uno User a scelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from inf_retriever import InfRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = InfRetriever(userId=1)     # User scelto arbitrariamente\n",
    "ir.computeUserPreferences(sample_size=10)   \n",
    "\n",
    "# Il metodo 'computeUserPreferences' esegue le seguenti operazioni:\n",
    "#   1) Recupera gli ID dei Film a cui lo User ha dato almeno '4.5' come punteggio\n",
    "#   2) Campiona 'sample_size' di questi Film -> Attenzione! Se il valore di 'sample_size' è maggiore del numero di Film 'candidati'\n",
    "#       questo automaticamente assume il valore 'int(0.67*len(candidati))'ArithmeticError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Strada, La (1954)',\n",
       " 'Lost in Translation (2003)',\n",
       " 'Pulp Fiction (1994)',\n",
       " 'Black Cat, White Cat (Crna macka, beli macor) (1998)',\n",
       " 'Run Lola Run (Lola rennt) (1998)',\n",
       " 'Teddy Bear (Mis) (1981)',\n",
       " 'Saragossa Manuscript, The (Rekopis znaleziony w Saragossie) (1965)',\n",
       " \"Spanish Apartment, The (L'auberge espagnole) (2002)\",\n",
       " 'The Magician (1958)',\n",
       " \"Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = ir.getMovieTitles()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>genres</th>\n",
       "      <th>plot</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>The Road</td>\n",
       "      <td>Federico Fellini</td>\n",
       "      <td>Drama</td>\n",
       "      <td>A care-free girl is sold to a traveling entert...</td>\n",
       "      <td>1954</td>\n",
       "      <td>Anthony Quinn, Giulietta Masina, Richard Basehart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>Lost in Translation</td>\n",
       "      <td>Sofia Coppola</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>A faded movie star and a neglected young woman...</td>\n",
       "      <td>2003</td>\n",
       "      <td>Bill Murray, Scarlett Johansson, Giovanni Ribisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>The lives of two mob hitmen, a boxer, a gangst...</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Travolta, Uma Thurman, Samuel L. Jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>Black Cat, White Cat</td>\n",
       "      <td>Emir Kusturica</td>\n",
       "      <td>Comedy, Crime, Romance</td>\n",
       "      <td>Matko and his son Zare live on the banks of th...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Bajram Severdzan, Srdjan 'Zika' Todorovic, Bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>Run Lola Run</td>\n",
       "      <td>Tom Tykwer</td>\n",
       "      <td>Action, Crime, Thriller</td>\n",
       "      <td>After a botched money delivery, Lola has 20 mi...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Franka Potente, Moritz Bleibtreu, Herbert Knaup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>Teddy Bear</td>\n",
       "      <td>Stanislaw Bareja</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The main character is the manager of a sport c...</td>\n",
       "      <td>1981</td>\n",
       "      <td>Stanislaw Tym, Barbara Burska, Christine Paul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>The Saragossa Manuscript</td>\n",
       "      <td>Wojciech Has</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>Upon finding a book that relates his grandfath...</td>\n",
       "      <td>1965</td>\n",
       "      <td>Zbigniew Cybulski, Iga Cembrzynska, Elzbieta C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>The Spanish Apartment</td>\n",
       "      <td>Cédric Klapisch</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>A strait-laced French student moves into an ap...</td>\n",
       "      <td>2002</td>\n",
       "      <td>Romain Duris, Judith Godrèche, Kelly Reilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>The Magician</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>A traveling magician and his assistants are pe...</td>\n",
       "      <td>1958</td>\n",
       "      <td>Max von Sydow, Ingrid Thulin, Gunnar Björnstrand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>Amélie</td>\n",
       "      <td>Jean-Pierre Jeunet</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>Despite being caught in her imaginative world,...</td>\n",
       "      <td>2001</td>\n",
       "      <td>Audrey Tautou, Mathieu Kassovitz, Rufus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title            director                    genres  \\\n",
       "7234                  The Road    Federico Fellini                     Drama   \n",
       "6711       Lost in Translation       Sofia Coppola             Comedy, Drama   \n",
       "296               Pulp Fiction   Quentin Tarantino              Crime, Drama   \n",
       "2843      Black Cat, White Cat      Emir Kusturica    Comedy, Crime, Romance   \n",
       "2692              Run Lola Run          Tom Tykwer   Action, Crime, Thriller   \n",
       "5767                Teddy Bear    Stanislaw Bareja                    Comedy   \n",
       "2632  The Saragossa Manuscript        Wojciech Has  Adventure, Comedy, Drama   \n",
       "6370     The Spanish Apartment     Cédric Klapisch    Comedy, Drama, Romance   \n",
       "7940              The Magician      Ingmar Bergman             Comedy, Drama   \n",
       "4973                    Amélie  Jean-Pierre Jeunet           Comedy, Romance   \n",
       "\n",
       "                                                   plot  year  \\\n",
       "7234  A care-free girl is sold to a traveling entert...  1954   \n",
       "6711  A faded movie star and a neglected young woman...  2003   \n",
       "296   The lives of two mob hitmen, a boxer, a gangst...  1994   \n",
       "2843  Matko and his son Zare live on the banks of th...  1998   \n",
       "2692  After a botched money delivery, Lola has 20 mi...  1998   \n",
       "5767  The main character is the manager of a sport c...  1981   \n",
       "2632  Upon finding a book that relates his grandfath...  1965   \n",
       "6370  A strait-laced French student moves into an ap...  2002   \n",
       "7940  A traveling magician and his assistants are pe...  1958   \n",
       "4973  Despite being caught in her imaginative world,...  2001   \n",
       "\n",
       "                                                   cast  \n",
       "7234  Anthony Quinn, Giulietta Masina, Richard Basehart  \n",
       "6711   Bill Murray, Scarlett Johansson, Giovanni Ribisi  \n",
       "296       John Travolta, Uma Thurman, Samuel L. Jackson  \n",
       "2843  Bajram Severdzan, Srdjan 'Zika' Todorovic, Bra...  \n",
       "2692    Franka Potente, Moritz Bleibtreu, Herbert Knaup  \n",
       "5767      Stanislaw Tym, Barbara Burska, Christine Paul  \n",
       "2632  Zbigniew Cybulski, Iga Cembrzynska, Elzbieta C...  \n",
       "6370        Romain Duris, Judith Godrèche, Kelly Reilly  \n",
       "7940   Max von Sydow, Ingrid Thulin, Gunnar Björnstrand  \n",
       "4973            Audrey Tautou, Mathieu Kassovitz, Rufus  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = ir.getMovieDetailsDF()\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = details[['director', 'genres', 'plot', 'year', 'cast']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarta Sezione -> Si chiede a Llama di \"riassumere\" le preferenze del nostro User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "I am going to give you a table composed by the following columns: 'director', 'genres', 'plot', 'year', 'cast'.\n",
    "I give you the task of summarizing the informations contained in each column of the table.\n",
    "\n",
    "Here are some further instructions:\n",
    "* The 'director' column contains the name of the director of the movies: report the two most common or famous directors.\n",
    "* The 'genres' column contains the genres of the movies: report the two or three most common genres.\n",
    "* The 'plot' column contains the plot of the movies: report the key concepts, events and people in the plots.\n",
    "* The 'year' column contains the year of the movies: indentify some patterns.\n",
    "* The 'cast' column contains the cast of the movies: report at most three of four of the most common and famous actors.\n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt = PromptTemplate.from_template(summarization_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = ({\"question\": RunnablePassthrough()} | summarization_prompt | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9907.85 ms\n",
      "llama_print_timings:      sample time =     153.64 ms /   107 runs   (    1.44 ms per token,   696.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7852.61 ms /   715 tokens (   10.98 ms per token,    91.05 tokens per second)\n",
      "llama_print_timings:        eval time =   27480.49 ms /   106 runs   (  259.25 ms per token,     3.86 tokens per second)\n",
      "llama_print_timings:       total time =   36198.87 ms /   821 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the table:\n",
      "\n",
      "**Director**: The directors mentioned in the table are:\n",
      "\n",
      "* Federico Fellini (7 times)\n",
      "* Sofia Coppola (1 time)\n",
      "* Quentin Tarantino (1 time)\n",
      "* Ingmar Bergman (1 time)\n",
      "\n",
      "**Actors and Actresses**: Some actors and actresses mentioned in the table are:\n",
      "\n",
      "* Anthony Quinn\n",
      "* Bill Murray\n",
      "* John Travolta\n",
      "* Franka Potente\n",
      "* Romain Duris\n",
      "* Max von Sydow\n",
      "* Sofia Coppola\n"
     ]
    }
   ],
   "source": [
    "request = f\"\"\"Summarize the following table: {details}\"\"\"\n",
    "resp = chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinta Sezione -> generazione delle Raccomandazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "You have to answer to the request in a precise way and strictly following what is asked: you MUST use the search results to build the answer.\n",
    "If the asked informations don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\"\n",
    "\n",
    "rec_prompt = PromptTemplate.from_template(rec_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | rec_prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9907.85 ms\n",
      "llama_print_timings:      sample time =     331.65 ms /   231 runs   (    1.44 ms per token,   696.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2707.78 ms /   195 tokens (   13.89 ms per token,    72.01 tokens per second)\n",
      "llama_print_timings:        eval time =   53899.09 ms /   230 runs   (  234.34 ms per token,     4.27 tokens per second)\n",
      "llama_print_timings:       total time =   58508.94 ms /   425 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies that correspond to at least one of the following features:\n",
      "\n",
      "* Director: Federico Fellini or Sofia Coppola or Quentin Tarantino or Ingmar Bergman\n",
      "* Cast: Anthony Quinn or Bill Murray or John Travolta or Audrey Tautou\n",
      "\n",
      "Here are some movies that correspond to at least one of these features:\n",
      "\n",
      "1. **8 1/2** (1963) - Directed by Federico Fellini, starring Marcello Mastroianni.\n",
      "\t* Score: 5\n",
      "2. **Lost in Translation** (2003) - Directed by Sofia Coppola, starring Bill Murray and Scarlett Johansson.\n",
      "\t* Score: 4\n",
      "3. **Pulp Fiction** (1994) - Directed by Quentin Tarantino, starring John Travolta, Samuel L. Jackson, and Uma Thurman.\n",
      "\t* Score: 5\n",
      "4. **The Seventh Seal** (1957) - Directed by Ingmar Bergman, starring Max von Sydow and Gunnar Björnstrand.\n",
      "\t* Score: 5\n",
      "\n",
      "These movies are highly acclaimed for their unique storytelling, cinematography, and direction.\n"
     ]
    }
   ],
   "source": [
    "request = \"\"\"Report me some movies which correspond to at least one of these features: \n",
    "* Director: Federico Fellini or Sofia Coppola or Quentin Tarantino or Ingmar Bergman\n",
    "* Cast: Anthony Quinn or Bill Murray or John Travolta or Audrey Tautou\n",
    "\n",
    "Give more importance to a movie if it corresponds to more than one of the listed features.\n",
    "After reporting the movies, explain why you chose them and assign a score (up to 5) to each movie basing on how much it corresponds to the listed features.\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)\n",
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutte le informazioni sui Film raccomandati sono corrette (verificate da IMDB):\n",
    "- 8 1/2 (id=1251) -> https://www.imdb.com/title/tt0056801/\n",
    "- Lost in Translation (id=6711) -> https://www.imdb.com/title/tt0335266/\n",
    "- Pulp Fiction (id=296) -> https://www.imdb.com/title/tt0110912/\n",
    "- The Seventh Seal (id=1237) -> https://www.imdb.com/title/tt0050976/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
