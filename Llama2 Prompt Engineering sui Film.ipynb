{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bKQIsIq-d8y"
   },
   "source": [
    "**Llama 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnV5UC7A2vBZ"
   },
   "source": [
    "The Llama 2 is a collection of pretrained and fine-tuned generative text models, ranging from 7 billion to 70 billion parameters, designed for dialogue use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC41zK5l3Abp"
   },
   "source": [
    " It outperforms open-source chat models on most benchmarks and is on par with popular closed-source models in human evaluations for helpfulness and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nobX9E83PjQ"
   },
   "source": [
    "[Llama 2 13B-chat](https://huggingface.co/meta-llama/Llama-2-13b-chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0K4QuEDH4CbY"
   },
   "source": [
    "`llama.cpp`'s objective is to run the LLaMA model with 4-bit integer quantization on MacBook. It is a plain C/C++ implementation optimized for Apple silicon and x86 architectures, supporting various integer quantization and BLAS libraries. Originally a web chat example, it now serves as a development playground for ggml library features.\n",
    "\n",
    "`GGML`, a C library for machine learning, facilitates the distribution of large language models (LLMs). It utilizes quantization to enable efficient LLM execution on consumer hardware. GGML files contain binary-encoded data, including version number, hyperparameters, vocabulary, and weights. The vocabulary comprises tokens for language generation, while the weights determine the LLM's size. Quantization reduces precision to optimize resource usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YC846SH5DOK"
   },
   "source": [
    "#  Quantized Models from the Hugging Face Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TD82wis5LGA"
   },
   "source": [
    "The Hugging Face community provides quantized models, which allow us to efficiently and effectively utilize the model on the T4 GPU. It is important to consult reliable sources before using any model.\n",
    "\n",
    "There are several variations available, but the ones that interest us are based on the GGLM library.\n",
    "\n",
    "We can see the different variations that Llama-2-13B-GGML has [here](https://huggingface.co/models?search=llama%202%20ggml).\n",
    "\n",
    "\n",
    "\n",
    "In this case, we will use the model called [Llama-2-13B-chat-GGML](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQZBmz7I5neU"
   },
   "source": [
    "#**Step 1: Install All the Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qJ90LnMv54Y-"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
    "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lOmpKB36RJh"
   },
   "source": [
    "#**Step 2: Import All the Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ak3ZtGjM6Wdp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "85XOzmui6rGN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haAb9kNm6J9n"
   },
   "source": [
    "#**Step 3: Download the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "f4f4b4a026a44b0f9fb2444e2aaba75e",
      "c4e454f8f20a464687c169f7a7a1fe9b",
      "31e741a46bd34f1e9f577c41376e2c08",
      "c2977c3862d845f99af150216ab05ff7",
      "65d7f3826be0482aa702e5c5f2be5eb2",
      "40accdff69474c0193be79d701f3c306",
      "e82c835d917042a7aba27feab6f0ecd8",
      "93e7404bda4246318d831d51d142326d",
      "e1fdf9e9541948d3a274072b73a0b800",
      "c612389940744049a31dd68b7d7ca300",
      "56b6f1132d404f8c822717b62def392d"
     ]
    },
    "id": "qBgdGV4b6MxG",
    "outputId": "75f1afda-3a0a-48da-b03d-8c473316fd08"
   },
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ6OYnI46kKq"
   },
   "source": [
    "#**Step 4: Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irftToUj6aWt",
    "outputId": "69f805ed-b559-4c7e-8160-81fa2e786ce7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/xodiec/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  =  483.30 MB (+  400.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x (640 kB + n_ctx x 160 B) = 360 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 40 repeating layers to GPU\n",
      "llama_model_load_internal: offloading non-repeating layers to GPU\n",
      "llama_model_load_internal: offloading v cache to GPU\n",
      "llama_model_load_internal: offloading k cache to GPU\n",
      "llama_model_load_internal: offloaded 43/43 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 9954 MB\n",
      "WARNING: failed to allocate 402.00 MB of pinned memory: out of memory\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "WARNING: failed to allocate 192.00 MB of pinned memory: out of memory\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=os.cpu_count(), # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=-1 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YG4Pylz662At",
    "outputId": "523e8ffe-a8a4-42a5-bb19-379c26f61228"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147483647"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the number of layers in GPU\n",
    "lcpp_llm.params.n_gpu_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE-M307R6_pT"
   },
   "source": [
    "#**Step 5: Create a Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I would like you to tell me the following informations related to the movie 'Sleepless in Seattle' (1993): Genre, Brief description of the plot, Director, Principal 4/6 members of the cast.\"\n",
    "prompt_template=f'''SYSTEM: You are a helpful assistant who's expert in the field of Cinema. For the requested movie, answer as follows:\n",
    "- Genre: use as least tokens as possible for this information\n",
    "- Description of the plot: report the main details of the movie's plot\n",
    "- Director: only report the director's name and surname\n",
    "- Principal 4/6 Members of the Cast: report names and surnames\n",
    "\n",
    "After you generated all these informations, end your response with the special token ['END'].\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT8pg6zt7QzA"
   },
   "source": [
    "#**Step 6: Generating the Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aF0qWUJ7OPK",
    "outputId": "f7d3a43a-5eed-4a22-c01b-48faf9c8a244"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1412.42 ms\n",
      "llama_print_timings:      sample time =    71.76 ms /   197 runs   (    0.36 ms per token,  2745.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1199.31 ms /   134 tokens (    8.95 ms per token,   111.73 tokens per second)\n",
      "llama_print_timings:        eval time = 11136.98 ms /   196 runs   (   56.82 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:       total time = 12748.67 ms\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=8192, temperature=0.1, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlJ1JgR68DDO",
    "outputId": "afdd2a1b-0684-40d7-a49d-d8c482041bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-b7892758-bfc9-49fb-89c3-9ee8775d0fb7', 'object': 'text_completion', 'created': 1713271041, 'model': '/home/xodiec/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin', 'choices': [{'text': \"SYSTEM: You are a helpful assistant who's expert in the field of Cinema. For the requested movie, answer as follows:\\n- Genre: use as least tokens as possible for this information\\n- Description of the plot: report the main details of the movie's plot\\n- Director: only report the director's name and surname\\n- Principal 4/6 Members of the Cast: report names and surnames\\n\\nAfter you generated all these informations, end your response with the special token ['END'].\\n\\nUSER: I would like you to tell me the following informations related to the movie 'Sleepless in Seattle' (1993): Genre, Brief description of the plot, Director, Principal 4/6 members of the cast.\\n\\nASSISTANT:\\n\\nGenre: Romantic Comedy [Rom-Com]\\n\\nDescription of the Plot: Sam Baldwin (Tom Hanks) is a recently widowed father who, still grieving the loss of his wife, decides to move to Seattle with his son Jonah. During a radio talk show, he shares his story and captures the attention of Annie Reed (Meg Ryan), a reporter from Baltimore who has given up on love. They start exchanging letters and eventually fall in love, but their long-distance relationship faces challenges as they try to meet for the first time.\\n\\nDirector: Nora Ephron\\n\\nPrincipal 4/6 Members of the Cast:\\n\\n* Tom Hanks (Sam Baldwin)\\n* Meg Ryan (Annie Reed)\\n* Ross Malinger (Jonah Baldwin)\\n* Victor Garber (Gregory Fulton)\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 174, 'completion_tokens': 196, 'total_tokens': 370}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qona58gX8oAn",
    "outputId": "9b86d544-79b0-4048-e636-bbb21dccedae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a helpful assistant who's expert in the field of Cinema. For the requested movie, answer as follows:\n",
      "- Genre: use as least tokens as possible for this information\n",
      "- Description of the plot: report the main details of the movie's plot\n",
      "- Director: only report the director's name and surname\n",
      "- Principal 4/6 Members of the Cast: report names and surnames\n",
      "\n",
      "After you generated all these informations, end your response with the special token ['END'].\n",
      "\n",
      "USER: I would like you to tell me the following informations related to the movie 'Sleepless in Seattle' (1993): Genre, Brief description of the plot, Director, Principal 4/6 members of the cast.\n",
      "\n",
      "ASSISTANT:\n",
      "\n",
      "Genre: Romantic Comedy [Rom-Com]\n",
      "\n",
      "Description of the Plot: Sam Baldwin (Tom Hanks) is a recently widowed father who, still grieving the loss of his wife, decides to move to Seattle with his son Jonah. During a radio talk show, he shares his story and captures the attention of Annie Reed (Meg Ryan), a reporter from Baltimore who has given up on love. They start exchanging letters and eventually fall in love, but their long-distance relationship faces challenges as they try to meet for the first time.\n",
      "\n",
      "Director: Nora Ephron\n",
      "\n",
      "Principal 4/6 Members of the Cast:\n",
      "\n",
      "* Tom Hanks (Sam Baldwin)\n",
      "* Meg Ryan (Annie Reed)\n",
      "* Ross Malinger (Jonah Baldwin)\n",
      "* Victor Garber (Gregory Fulton)\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "31e741a46bd34f1e9f577c41376e2c08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93e7404bda4246318d831d51d142326d",
      "max": 9763701888,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1fdf9e9541948d3a274072b73a0b800",
      "value": 9763701888
     }
    },
    "40accdff69474c0193be79d701f3c306": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b6f1132d404f8c822717b62def392d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65d7f3826be0482aa702e5c5f2be5eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93e7404bda4246318d831d51d142326d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2977c3862d845f99af150216ab05ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c612389940744049a31dd68b7d7ca300",
      "placeholder": "​",
      "style": "IPY_MODEL_56b6f1132d404f8c822717b62def392d",
      "value": " 9.76G/9.76G [01:17&lt;00:00, 41.0MB/s]"
     }
    },
    "c4e454f8f20a464687c169f7a7a1fe9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40accdff69474c0193be79d701f3c306",
      "placeholder": "​",
      "style": "IPY_MODEL_e82c835d917042a7aba27feab6f0ecd8",
      "value": "llama-2-13b-chat.ggmlv3.q5_1.bin: 100%"
     }
    },
    "c612389940744049a31dd68b7d7ca300": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1fdf9e9541948d3a274072b73a0b800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e82c835d917042a7aba27feab6f0ecd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4f4b4a026a44b0f9fb2444e2aaba75e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4e454f8f20a464687c169f7a7a1fe9b",
       "IPY_MODEL_31e741a46bd34f1e9f577c41376e2c08",
       "IPY_MODEL_c2977c3862d845f99af150216ab05ff7"
      ],
      "layout": "IPY_MODEL_65d7f3826be0482aa702e5c5f2be5eb2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
