{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16a5dd1-e966-4fb4-b6f4-0dee245abd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd0963e-abb1-4fa9-bea8-617bf4a3ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_folder = \"./movie_text_data/\"\n",
    "files = os.listdir(files_folder)\n",
    "\n",
    "docs = []\n",
    "\n",
    "for file in files:\n",
    "    loader = TextLoader(files_folder + file)\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cd0a36-42f8-4a05-b3f5-65f61f6b0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings_llm = OllamaEmbeddings(model=\"llama3\") #base_url = 'http://localhost:11434'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ba5679-7903-4263-acef-42d6c1b536cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab872ff9-c012-484c-8ae7-8c10b7416a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f621573f250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_index = FAISS.from_documents(documents, embeddings_llm)\n",
    "\n",
    "vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784a884-d545-4b4a-99f9-de22fdc40e7c",
   "metadata": {},
   "source": [
    "### There are 3 functions to create index.\n",
    "\n",
    "from_documents()\n",
    "from_embeddings()\n",
    "from_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e95c47-7988-4723-a5a0-6835ca794ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever()\n",
    "\n",
    "relevant_docs = retriever.invoke({\"input\": \"Tales from the Hood\"})\n",
    "\n",
    "len(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db176719-fe48-48fb-8eea-d23bbd302009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Title: What's Eating Gilbert Grape\\nDirector: Lasse Hallström\\nGenres: Drama\\nBrief Plot: A young man in a small Midwestern town struggles to care for his mentally-disabled younger brother and morbidly obese mother while attempting to pursue his own happiness.\\nYear: 1993\\nStars: Johnny Depp, Leonardo DiCaprio, Juliette Lewis\", metadata={'source': './movie_text_data/movie_tt0108550.txt'}),\n",
       " Document(page_content='Title: Casino\\nDirector: Martin Scorsese\\nGenres: Crime, Drama\\nBrief Plot: In Las Vegas, two best friends - a casino executive and a mafia enforcer - compete for a gambling empire and a fast-living, fast-loving socialite.\\nYear: 1995\\nStars: Robert De Niro, Sharon Stone, Joe Pesci', metadata={'source': './movie_text_data/movie_tt0112641.txt'}),\n",
       " Document(page_content='Title: Ace Ventura: Pet Detective\\nDirector: Tom Shadyac\\nGenres: Comedy\\nBrief Plot: A goofy detective specializing in animals goes in search of the missing mascot of the Miami Dolphins.\\nYear: 1994\\nStars: Jim Carrey, Courteney Cox, Sean Young', metadata={'source': './movie_text_data/movie_tt0109040.txt'}),\n",
       " Document(page_content='Title: Free Willy\\nDirector: Simon Wincer\\nGenres: Adventure, Drama, Family\\nBrief Plot: When a boy learns that a beloved killer whale is to be killed by the aquarium owners, the boy risks everything to free the whale.\\nYear: 1993\\nStars: Jason James Richter, Lori Petty, Michael Madsen', metadata={'source': './movie_text_data/movie_tt0106965.txt'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28be8564-3f4f-4f97-b35c-fc1a2de3a4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m relevant_docs:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "for doc in relevant_docs:\n",
    "    print(f\"Title : {doc.metadata['title']}, Source: {doc.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e981302-4145-4164-bc40-1d2cb7d047d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am familiar with Claude 3. It's a conversational AI model from Anthropic, the latest one in their series of Claude models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "(32 tokens)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'll stop here since I reached the token limit!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "It seems I didn't quite reach the 32-token limit after all!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here's my answer again, within the 32-token limit:\n",
      "\n",
      "Yes, I know about Claude 3. It's a conversational AI model from Anthropic.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I got it right this time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( Done!)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'll stop here since I reached the token limit!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "(32 tokens)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Let me try again, within the 32-token limit:\n",
      "\n",
      "Yes, I know about Claude 3.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'll stop now that I've reached the limit!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Done!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Final answer: Yes, I know about Claude 3.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "That's it!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think that's all for this conversation!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Done!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Wait, what was the question again?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Ha ha, good one!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "( End of conversation)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I think I've been asked that already!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Indeed!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Goodbye!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "See you next time<|eot_id|>assistant<|eot_id|><|eot_id|><|eot_id|>  https  <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|><|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|><|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|> <|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|> <|eot_id|><|eot_id|><|eot_id|> <|eot_id|><|eot_id|> <|eot_id|> <|eot_id|><|eot_id|><|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|><|eot_id|><|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|><|eot_id|> <|eot_id|><|eot_id|><|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> <|eot_id|> \u0006� \u0005� \u0019 \u0006                     \t  \t \t  \t \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based on the provided context and your internal knowledge.\n",
    "Give priority to context and if you are not sure then say you are not aware of topic.\n",
    "Stop your generation when you end the concept: never generate more than 32 tokens.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "#document_chain  = prompt | llm \n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "response = document_chain.invoke({\n",
    "    \"input\": \"Do you know about Claude 3?\",\n",
    "    \"context\": [Document(page_content=\"Claude 3 is latest Conversational AI Model from Anthropic.\")]\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a291a3-3744-4c50-a34b-df67a1976c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x109aa6990>), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template='\\nAnswer the following question based on the provided context and your internal knowledge.\\nGive priority to context and if you are not sure then say you are not aware of topic:\\n\\n<context>\\n{context}\\n</context>\\n\\nQuestion: {input}\\n'))])\n",
       "            | Ollama(model='llama3')\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f10315bb-00c0-49fb-8ebc-c28cedd0bf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Do you know about Claude 3?\"})\n",
    "\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf54ec17-8560-4b48-a680-41890bb1e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude 3 is a powerful language model developed by Anthropic, a leading AI research organization. It's designed to be highly intelligent and capable of understanding complex tasks, with three variants: Opus, Sonnet, and Haiku.\n",
      "\n",
      "Opus is the most intelligent model, ideal for complex analysis, longer tasks with multiple steps, and higher-order math and coding tasks.\n",
      "\n",
      "Sonnet is engineered for high endurance in large-scale AI deployments, offering a balance between intelligence and speed at a lower cost compared to its peers.\n",
      "\n",
      "Haiku is the fastest and most compact model, perfect for near-instant responsiveness and answering simple queries and requests quickly.\n",
      "\n",
      "Each variant has its unique strengths and use cases, making Claude 3 an excellent choice for various applications, from coding assistance to data processing and content moderation.\n",
      "\n",
      "What would you like to know more about Claude 3 or how it can be applied in a specific context?\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3f2d28-3b24-4e68-ad94-f63417e3508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Introducing the next generation of Claude \\ Anthropic, Source: https://www.anthropic.com/news/claude-3-family\n",
      "Title : Claude \\ Anthropic, Source: https://www.anthropic.com/claude\n",
      "Title : Claude 2 \\ Anthropic, Source: https://www.anthropic.com/news/claude-2\n",
      "Title : Introducing the next generation of Claude \\ Anthropic, Source: https://www.anthropic.com/news/claude-3-family\n"
     ]
    }
   ],
   "source": [
    "for doc in response[\"context\"]:\n",
    "    print(f\"Title : {doc.metadata['title']}, Source: {doc.metadata['source']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
