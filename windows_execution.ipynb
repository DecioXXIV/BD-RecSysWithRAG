{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione del Device\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prima Sezione -> Interazione con Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 58022\n",
      "Required Time: 0:07:07.848427\n"
     ]
    }
   ],
   "source": [
    "# Questo Blocco di Codice serve per effettuare lo Splitting dei Documenti memorizzati in \"movie_text_data\"\n",
    "docs = list()\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "for file in os.listdir('./movie_text_data/'):\n",
    "    loader = TextLoader(f'./movie_text_data/{file}')\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)  # DA OTTIMIZZARE\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione del Modello di Embedding -> all-MiniLM-L12-v2 (HuggingFace, len(Spazio Latente)=384)\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': device}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connessione a Milvus (deve essere prima fatto partire il Container su Docker!)\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    collection_name=\"MovieTextData\",\n",
    "    drop_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Time: 0:01:30.029326\n"
     ]
    }
   ],
   "source": [
    "# Attenzione!!! Il seguente Blocco di Codice reinizializza Milvus ed esegue il Caricamento dei Documenti memorizzati in 'all_splits'ArithmeticError\n",
    "start = datetime.now()\n",
    "\n",
    "vector_db = Milvus.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    connection_args={'host':'127.0.0.1', 'port':'19530'},\n",
    "    collection_name=\"MovieTextData\",\n",
    "    drop_old=True\n",
    ")\n",
    "\n",
    "print(\"Required Time:\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default collection name - MovieTextData\n",
      "Default search params - {'metric_type': 'L2', 'params': {'ef': 10}}\n",
      "Default index params - None\n"
     ]
    }
   ],
   "source": [
    "# Esegui il seguente Blocco di Codice per ottenere informazioni sulla Collezione in Milvus\n",
    "print(f\"Default collection name - {vector_db.collection_name}\")\n",
    "print(f\"Default search params - {vector_db.search_params}\")\n",
    "print(f\"Default index params - {vector_db.index_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seconda Sezione -> Inizializzazione di Llama3-8b-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/Meta-Llama-3-8B-Instruct-Q6_K.gguf\"\n",
    "n_threads = int(os.cpu_count()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ./models/Meta-Llama-3-8B-Instruct-Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   410.98 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  5871.99 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 1024\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '18', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|end_of_text|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        n_gpu_layers=-1,\n",
    "        n_batch=1024,\n",
    "        temperature=0.1,\n",
    "        n_threads=n_threads,\n",
    "        max_tokens=8192,\n",
    "        n_ctx=2048,\n",
    "        # f16_kv=True,\n",
    "        # callback_manager=CallbackManager(StreamingStdOutCallbackHandler()),\n",
    "        verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terza Sezione -> Recupero delle Preferenze di un certo User (per ora, uno User a scelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from inf_retriever import InfRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = InfRetriever(userId=24)     # User scelto arbitrariamente\n",
    "ir.computeUserPreferences(sample_size=100)   \n",
    "\n",
    "# Il metodo 'computeUserPreferences' esegue le seguenti operazioni:\n",
    "#   1) Recupera gli ID dei Film a cui lo User ha dato almeno '4.5' come punteggio\n",
    "#   2) Campiona 'sample_size' di questi Film -> Attenzione! Se il valore di 'sample_size' è maggiore del numero di Film 'candidati'\n",
    "#       questo automaticamente assume il valore 'int(0.67*len(candidati))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Usual Suspects, The (1995)',\n",
       " 'Shawshank Redemption, The (1994)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'Jungle Book, The (1967)',\n",
       " 'Fight Club (1999)',\n",
       " 'Gone in 60 Seconds (2000)',\n",
       " 'Dark Knight, The (2008)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = ir.getMovieTitles()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>genres</th>\n",
       "      <th>plot</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>The sole survivor of a pier shoot-out tells th...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Kevin Spacey, Gabriel Byrne, Chazz Palminteri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Over the course of several years, two convicts...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Tim Robbins, Morgan Freeman, Bob Gunton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "      <td>In German-occupied Poland during World War II,...</td>\n",
       "      <td>1993</td>\n",
       "      <td>Liam Neeson, Ralph Fiennes, Ben Kingsley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>The Jungle Book</td>\n",
       "      <td>Wolfgang Reitherman</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>Bagheera the Panther and Baloo the Bear have a...</td>\n",
       "      <td>1967</td>\n",
       "      <td>Phil Harris, Sebastian Cabot, Louis Prima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>Drama</td>\n",
       "      <td>An insomniac office worker and a devil-may-car...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Brad Pitt, Edward Norton, Meat Loaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>Gone in 60 Seconds</td>\n",
       "      <td>Dominic Sena</td>\n",
       "      <td>Action, Crime, Thriller</td>\n",
       "      <td>A retired master car thief must come back to t...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Nicolas Cage, Angelina Jolie, Giovanni Ribisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58559</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christian Bale, Heath Ledger, Aaron Eckhart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title             director  \\\n",
       "50           The Usual Suspects         Bryan Singer   \n",
       "318    The Shawshank Redemption       Frank Darabont   \n",
       "527            Schindler's List     Steven Spielberg   \n",
       "2078            The Jungle Book  Wolfgang Reitherman   \n",
       "2959                 Fight Club        David Fincher   \n",
       "3717         Gone in 60 Seconds         Dominic Sena   \n",
       "58559           The Dark Knight    Christopher Nolan   \n",
       "\n",
       "                             genres  \\\n",
       "50            Crime, Drama, Mystery   \n",
       "318                           Drama   \n",
       "527       Biography, Drama, History   \n",
       "2078   Animation, Adventure, Comedy   \n",
       "2959                          Drama   \n",
       "3717        Action, Crime, Thriller   \n",
       "58559          Action, Crime, Drama   \n",
       "\n",
       "                                                    plot  year  \\\n",
       "50     The sole survivor of a pier shoot-out tells th...  1995   \n",
       "318    Over the course of several years, two convicts...  1994   \n",
       "527    In German-occupied Poland during World War II,...  1993   \n",
       "2078   Bagheera the Panther and Baloo the Bear have a...  1967   \n",
       "2959   An insomniac office worker and a devil-may-car...  1999   \n",
       "3717   A retired master car thief must come back to t...  2000   \n",
       "58559  When the menace known as the Joker wreaks havo...  2008   \n",
       "\n",
       "                                                cast  \n",
       "50     Kevin Spacey, Gabriel Byrne, Chazz Palminteri  \n",
       "318          Tim Robbins, Morgan Freeman, Bob Gunton  \n",
       "527         Liam Neeson, Ralph Fiennes, Ben Kingsley  \n",
       "2078       Phil Harris, Sebastian Cabot, Louis Prima  \n",
       "2959             Brad Pitt, Edward Norton, Meat Loaf  \n",
       "3717   Nicolas Cage, Angelina Jolie, Giovanni Ribisi  \n",
       "58559    Christian Bale, Heath Ledger, Aaron Eckhart  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = ir.getMovieDetailsDF()\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = details['title'].tolist()\n",
    "details = details[['director', 'genres', 'plot', 'year', 'cast']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarta Sezione -> Si chiede a Llama di \"riassumere\" le preferenze del nostro User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "I am going to give you a table composed by the following columns: 'director', 'genres', 'plot', 'year', 'cast'.\n",
    "I give you the task of summarizing the informations contained in each column of the table.\n",
    "\n",
    "Here are some further instructions:\n",
    "* The 'director' column contains the name of the director of the movies: report the two most common directors.\n",
    "* The 'genres' column contains the genres of the movies: report the two or three most common genres.\n",
    "* The 'plot' column contains the plot of the movies: report the key concepts, events and people in the plots.\n",
    "* The 'year' column contains the year of the movies: indentify some patterns.\n",
    "* The 'cast' column contains the cast of the movies: report not more than three of four of the most common actors.\n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt = PromptTemplate.from_template(summarization_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = ({\"question\": RunnablePassthrough()} | summarization_prompt | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10920.70 ms\n",
      "llama_print_timings:      sample time =     243.47 ms /   166 runs   (    1.47 ms per token,   681.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.45 ms /   552 tokens (    1.41 ms per token,   708.20 tokens per second)\n",
      "llama_print_timings:        eval time =    4516.06 ms /   165 runs   (   27.37 ms per token,    36.54 tokens per second)\n",
      "llama_print_timings:       total time =    6650.16 ms /   717 tokens\n"
     ]
    }
   ],
   "source": [
    "request = f\"\"\"Summarize the following table: {details}\"\"\"\n",
    "resp = chain.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the table:\n",
      "\n",
      "**Director:** The two most common directors are Bryan Singer and Frank Darabont.\n",
      "\n",
      "**Genre:** The three most common genres are Crime, Drama, and Mystery.\n",
      "\n",
      "**Plot:** Some key concepts, events, and people in the plots include pier shoot-outs, prison life, World War II, and a battle between good and evil.\n",
      "\n",
      "**Year:** The years represented in the table range from 1967 to 2008.\n",
      "\n",
      "**Cast:** Some notable actors who have appeared in these movies include Kevin Spacey, Gabriel Byrne, Tim Robbins, Morgan Freeman, Liam Neeson, Ralph Fiennes, Ben Kingsley, Brad Pitt, Edward Norton, Meat Loaf, Nicolas Cage, Angelina Jolie, Giovanni Ribisi, Christian Bale, Heath Ledger, and Aaron Eckhart.\n"
     ]
    }
   ],
   "source": [
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinta Sezione -> generazione delle Raccomandazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_template = \"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an helpful AI assistant, which is expert about the field of Movies and Cinema.\n",
    "You have to answer to the request in a precise way and strictly following what is asked: you MUST use the search results to build the answer.\n",
    "If the asked informations don't exist within the search results, DON'T INVENT THEM AND JUST ANSWER 'I don't know how to answer to this question'. \n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "<|eot_id|>\n",
    "\n",
    "<start_header_id|>assistant<|end_header_id|>\n",
    "Answer: \"\"\"\n",
    "\n",
    "rec_prompt = PromptTemplate.from_template(rec_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | rec_prompt | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10920.70 ms\n",
      "llama_print_timings:      sample time =     316.65 ms /   219 runs   (    1.45 ms per token,   691.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    5682.96 ms /   219 runs   (   25.95 ms per token,    38.54 tokens per second)\n",
      "llama_print_timings:       total time =    7494.70 ms /   220 tokens\n"
     ]
    }
   ],
   "source": [
    "request = f\"\"\"Report me some movies which correspond to at least one of these features: \n",
    "* Director: Bryan Singer or Frank Darabont \n",
    "* Genre: Crime, Drama, Mystery\n",
    "* Plot: 'shoot-outs', 'prison life', 'World War II', 'battle between good and evil'\n",
    "* Cast: Kevin Spacey or Morgan Freeman or Liam Neeson or Ralph Fiennes or Ben Kingsley\n",
    "\n",
    "Give more importance to a movie if it corresponds to more than one of the listed features.\n",
    "After reporting the movies, explain why you chose them.\n",
    "\n",
    "You must not report the movies whose titles are in the following list: {titles}\"\"\"\n",
    "\n",
    "resp = rag_chain.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Movies that correspond to at least one of the listed features:\n",
      "\n",
      "1. **X-Men** (2000) - Director: Bryan Singer; Genre: Superhero, Action; Plot: Battle between good and evil; Cast: Hugh Jackman, Patrick Stewart, Ian McKellen.\n",
      "2. **The Green Mile** (1999) - Director: Frank Darabont; Genre: Drama, Fantasy; Plot: Prison life; Cast: Tom Hanks, Michael Clarke Duncan, Sam Rockwell.\n",
      "3. **Saving Private Ryan** (1998) - Director: Steven Spielberg; Genre: War, Drama; Plot: World War II; Cast: Tom Hanks, Matt Damon, Vin Diesel.\n",
      "\n",
      "I chose these movies because they correspond to at least one of the listed features. For example, **X-Men** corresponds to the feature \"Director: Bryan Singer\" and also to the feature \"Genre: Superhero, Action\". Similarly, **The Green Mile** corresponds to the feature \"Director: Frank Darabont\" and also to the feature \"Genre: Drama, Fantasy\".\n"
     ]
    }
   ],
   "source": [
    "print(str(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Usual Suspects',\n",
       " 'The Shawshank Redemption',\n",
       " \"Schindler's List\",\n",
       " 'The Jungle Book',\n",
       " 'Fight Club',\n",
       " 'Gone in 60 Seconds',\n",
       " 'The Dark Knight']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutte le informazioni sui Film raccomandati sono corrette (verificate da IMDB):\n",
    "- 8 1/2 (id=1251) -> https://www.imdb.com/title/tt0056801/\n",
    "- Lost in Translation (id=6711) -> https://www.imdb.com/title/tt0335266/\n",
    "- Pulp Fiction (id=296) -> https://www.imdb.com/title/tt0110912/\n",
    "- The Seventh Seal (id=1237) -> https://www.imdb.com/title/tt0050976/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
